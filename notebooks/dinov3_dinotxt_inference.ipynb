{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f45c6a9a",
      "metadata": {
        "id": "f45c6a9a",
        "outputId": "45a027d2-cf8b-4392-ab68-b48a23c4a6a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ARGO_Vision_CODEMOTION_2025'...\n",
            "remote: Enumerating objects: 263, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 263 (delta 37), reused 22 (delta 11), pack-reused 192 (from 1)\u001b[K\n",
            "Receiving objects: 100% (263/263), 45.78 MiB | 25.77 MiB/s, done.\n",
            "Resolving deltas: 100% (143/143), done.\n",
            "Cloning into 'dinov3'...\n",
            "remote: Enumerating objects: 409, done.\u001b[K\n",
            "remote: Counting objects: 100% (198/198), done.\u001b[K\n",
            "remote: Compressing objects: 100% (136/136), done.\u001b[K\n",
            "remote: Total 409 (delta 124), reused 62 (delta 62), pack-reused 211 (from 2)\u001b[K\n",
            "Receiving objects: 100% (409/409), 9.83 MiB | 17.69 MiB/s, done.\n",
            "Resolving deltas: 100% (156/156), done.\n",
            "Obtaining file:///content/ARGO_Vision_CODEMOTION_2025\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from CODEMOTION_2025==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from CODEMOTION_2025==0.1.0) (1.6.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from CODEMOTION_2025==0.1.0) (3.1.0)\n",
            "Collecting kornia (from CODEMOTION_2025==0.1.0)\n",
            "  Downloading kornia-0.8.1-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting kornia_rs>=0.1.9 (from kornia->CODEMOTION_2025==0.1.0)\n",
            "  Downloading kornia_rs-0.1.9-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kornia->CODEMOTION_2025==0.1.0) (25.0)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from kornia->CODEMOTION_2025==0.1.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->CODEMOTION_2025==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->CODEMOTION_2025==0.1.0) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->CODEMOTION_2025==0.1.0) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->CODEMOTION_2025==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.9.1->kornia->CODEMOTION_2025==0.1.0) (3.0.3)\n",
            "Downloading kornia-0.8.1-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.9-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: CODEMOTION_2025\n",
            "  Building editable for CODEMOTION_2025 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for CODEMOTION_2025: filename=codemotion_2025-0.1.0-0.editable-py3-none-any.whl size=2909 sha256=5b94dc9d1ec06e676457a803978144edd73795bf61011f69769526d011d21a50\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p_0kg9cu/wheels/5b/cb/24/68e4d6865367b2eb40d237767b8b626120727f49411638f36e\n",
            "Successfully built CODEMOTION_2025\n",
            "Installing collected packages: kornia_rs, kornia, CODEMOTION_2025\n",
            "Successfully installed CODEMOTION_2025-0.1.0 kornia-0.8.1 kornia_rs-0.1.9\n",
            "Obtaining file:///content/dinov3\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from dinov3==0.0.1)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from dinov3==0.0.1) (2.3.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from dinov3==0.0.1) (2024.11.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from dinov3==0.0.1) (1.6.1)\n",
            "Collecting submitit (from dinov3==0.0.1)\n",
            "  Downloading submitit-1.5.3-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from dinov3==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from dinov3==0.0.1) (2.8.0+cu126)\n",
            "Collecting torchmetrics (from dinov3==0.0.1)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from dinov3==0.0.1) (0.23.0+cu126)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->dinov3==0.0.1) (0.2.14)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf->dinov3==0.0.1) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf->dinov3==0.0.1) (6.0.3)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->dinov3==0.0.1) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->dinov3==0.0.1) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->dinov3==0.0.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->dinov3==0.0.1) (3.6.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from submitit->dinov3==0.0.1) (3.1.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.12/dist-packages (from submitit->dinov3==0.0.1) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->dinov3==0.0.1) (3.4.0)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics->dinov3==0.0.1) (25.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->dinov3==0.0.1)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->dinov3==0.0.1) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->dinov3==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->dinov3==0.0.1) (3.0.3)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading submitit-1.5.3-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: dinov3\n",
            "  Building editable for dinov3 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dinov3: filename=dinov3-0.0.1-0.editable-py3-none-any.whl size=13762 sha256=8d2760e39ec655eb9ad948e2390de7e155212595f356ea7816484303ba5fe25b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f294of51/wheels/6a/8e/23/328be284c861656d92e8e40a2e9861bd5a461bfdcbb16a432e\n",
            "Successfully built dinov3\n",
            "Installing collected packages: submitit, lightning-utilities, ftfy, torchmetrics, dinov3\n",
            "Successfully installed dinov3-0.0.1 ftfy-6.3.1 lightning-utilities-0.15.2 submitit-1.5.3 torchmetrics-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/plana93/ARGO_Vision_CODEMOTION_2025.git\n",
        "!git clone https://github.com/facebookresearch/dinov3.git\n",
        "!pip install -e ARGO_Vision_CODEMOTION_2025\n",
        "!pip install -e dinov3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "231db286",
      "metadata": {
        "id": "231db286"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "sys.path.append(\"./ARGO_Vision_CODEMOTION_2025\")\n",
        "sys.path.append(\"./dinov3\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from typing import Any, Tuple, Union, Optional\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "import inspect\n",
        "\n",
        "# from dinov3.hub.dinotxt import dinov3_vitl16_dinotxt_tet1280d20h24l #todo fix\n",
        "\n",
        "from codemotion2025.utils.dinov3_utils import last_layer_patch_features_v3, _infer_patch_size\n",
        "import timm\n",
        "\n",
        "# model, tokenizer = dinov3_vitl16_dinotxt_tet1280d20h24l()"
      ],
      "metadata": {
        "id": "7Ei7Yk8ckpk0",
        "outputId": "43d0d559-34a1-4a15-bb97-e66ddfded983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "id": "7Ei7Yk8ckpk0",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'codemotion2025'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2761089339.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# from dinov3.hub.dinotxt import dinov3_vitl16_dinotxt_tet1280d20h24l #todo fix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcodemotion2025\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdinov3_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlast_layer_patch_features_v3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_infer_patch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'codemotion2025'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# =============== utils ===============\n",
        "\n",
        "\n",
        "def _timm_forward_all_tokens(timm_model: nn.Module, x: torch.Tensor, verbose: bool = False) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Call timm ViT's forward_features and robustly extract **all tokens** (B, N_all, C),\n",
        "    including CLS and possible register tokens (as used by DINOv3).\n",
        "    \"\"\"\n",
        "    sig = inspect.signature(timm_model.forward_features)\n",
        "    kwargs = {}\n",
        "    if \"return_all_tokens\" in sig.parameters:\n",
        "        kwargs[\"return_all_tokens\"] = True\n",
        "    if \"return_dict\" in sig.parameters:\n",
        "        kwargs[\"return_dict\"] = True\n",
        "\n",
        "    out = timm_model.forward_features(x, **kwargs)\n",
        "\n",
        "    if isinstance(out, dict):\n",
        "        # common keys used by timm models\n",
        "        tokens = out.get(\"x\", None) or out.get(\"tokens\", None)\n",
        "        if tokens is not None and tokens.ndim == 3:\n",
        "            if verbose:\n",
        "                print(f\"[timm] forward_features(dict) -> tokens {tuple(tokens.shape)}\")\n",
        "            return tokens\n",
        "        # some variants may expose a feature map instead of tokens\n",
        "        fmap = out.get(\"feature_maps\", None)\n",
        "        if fmap:\n",
        "            # last fmap assumed: (B, C, H, W) -> convert to tokens with CLS? Not available.\n",
        "            # In that rare case, we flatten spatial tokens (no CLS) to (B, H*W, C).\n",
        "            y = fmap[-1]  # (B, C, H, W)\n",
        "            B, C, H, W = y.shape\n",
        "            y = y.permute(0, 2, 3, 1).reshape(B, H * W, C)\n",
        "            if verbose:\n",
        "                print(f\"[timm] forward_features(dict) -> fmap {tuple(fmap[-1].shape)} -> tokens {tuple(y.shape)} (no CLS)\")\n",
        "            return y\n",
        "        raise ValueError(\"forward_features returned dict but no 'x'/'tokens' or 'feature_maps'.\")\n",
        "    elif isinstance(out, torch.Tensor):\n",
        "        if out.ndim == 3:\n",
        "            if verbose:\n",
        "                print(f\"[timm] forward_features(tensor) -> tokens {tuple(out.shape)}\")\n",
        "            return out\n",
        "        elif out.ndim == 4:\n",
        "            # (B, C, H, W) : flatten to tokens (no CLS)\n",
        "            B, C, H, W = out.shape\n",
        "            y = out.permute(0, 2, 3, 1).reshape(B, H * W, C)\n",
        "            if verbose:\n",
        "                print(f\"[timm] forward_features(tensor fmap) -> {tuple(out.shape)} -> tokens {tuple(y.shape)} (no CLS)\")\n",
        "            return y\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected forward_features tensor shape: {tuple(out.shape)}\")\n",
        "    else:\n",
        "        raise TypeError(f\"Unexpected forward_features output type: {type(out)}\")\n",
        "\n",
        "\n",
        "# =============== adapter ===============\n",
        "\n",
        "class TimmDINOv3BackboneAdapter(nn.Module):\n",
        "    \"\"\"\n",
        "    Tiny adapter to make a timm DINOv3 ViT look like the original DINO backbone expected by DINOTxt:\n",
        "      - .forward_features(x) -> (B, N_all, C) tokens (CLS + patch + possible registers)\n",
        "      - .num_prefix_tokens property (CLS + registers)\n",
        "      - .embed_dim property (C)\n",
        "      - (opzionale) .patch_size (int)\n",
        "\n",
        "    NOTE: We do **not** remove prefix tokens here: higher-level heads (like DINOTxt)\n",
        "    can decide whether to use CLS / patch tokens. Keeping all tokens is safest.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, timm_name: str, device: Union[str, torch.device] = \"cpu\", pretrained: bool = True, verbose: bool = False):\n",
        "        super().__init__()\n",
        "        self.verbose = verbose\n",
        "        self.model = timm.create_model(timm_name, pretrained=pretrained)\n",
        "        self.model.eval().to(device)\n",
        "\n",
        "        # common attributes the upper stack may look for\n",
        "        self.embed_dim = getattr(self.model, \"num_features\", None) or getattr(self.model, \"embed_dim\", None)\n",
        "        if self.embed_dim is None:\n",
        "            # heuristic: many ViTs have 'embed_dim' on .blocks[0].norm1.normalized_shape[0], but num_features is safer\n",
        "            raise AttributeError(\"Cannot infer embed_dim from timm model.\")\n",
        "\n",
        "        # try to detect #prefix tokens (CLS + registers)\n",
        "        # Many DINOv3 timm ckpts expose 'num_prefix_tokens' or 'num_register_tokens'\n",
        "        n_regs = getattr(self.model, \"num_register_tokens\", 0)\n",
        "        self.num_prefix_tokens = 1 + int(n_regs)  # assume 1 CLS + N reg\n",
        "        self.patch_size = _infer_patch_size(self.model)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"[adapter] Loaded timm '{timm_name}'  embed_dim={self.embed_dim}  patch={self.patch_size}  prefix_tokens={self.num_prefix_tokens}\")\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward_features(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Return **all tokens** (B, N_all, C).\n",
        "        Upstream logic can decide whether to use CLS or only patch tokens.\n",
        "        \"\"\"\n",
        "        tokens = _timm_forward_all_tokens(self.model, x, verbose=self.verbose)  # (B, N_all, C)\n",
        "        # sanity check: spatial grid should be consistent with input size & patch size\n",
        "        B, N_all, C = tokens.shape\n",
        "        H, W = x.shape[-2:]\n",
        "        Hp, Wp = H // self.patch_size, W // self.patch_size\n",
        "        n_expected = Hp * Wp + self.num_prefix_tokens\n",
        "        if self.verbose:\n",
        "            print(f\"[adapter] forward_features -> tokens={tokens.shape}  input={(H,W)}  grid={Hp}x{Wp}  expected_N={n_expected}\")\n",
        "        # Do not hard-fail if mismatch (some models hide registers); just warn.\n",
        "        if n_expected != N_all and self.verbose:\n",
        "            print(f\"[adapter][warn] tokens mismatch: got {N_all}, expected {n_expected} (prefix={self.num_prefix_tokens}, grid={Hp}x{Wp})\")\n",
        "        return tokens\n",
        "\n",
        "    # For compatibility if someone calls `.forward`\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.forward_features(x)\n",
        "\n",
        "\n",
        "# =============== factory ===============\n",
        "\n",
        "def build_timm_dinov3_backbone(\n",
        "    timm_name: str = \"vit_large_patch16_dinov3.lvd_1689m\",\n",
        "    *,\n",
        "    pretrained: bool = True,\n",
        "    device: Union[str, torch.device] = \"cpu\",\n",
        "    verbose: bool = False,\n",
        ") -> nn.Module:\n",
        "    \"\"\"\n",
        "    Create a timm DINOv3 backbone wrapped in the adapter so it looks like the original DINOV3 backbone.\n",
        "    \"\"\"\n",
        "    backbone = TimmDINOv3BackboneAdapter(\n",
        "        timm_name=timm_name, device=device, pretrained=pretrained, verbose=verbose\n",
        "    )\n",
        "    if verbose:\n",
        "        print(f\"[build] timm DINOv3 backbone ok → {timm_name}\")\n",
        "    return backbone\n"
      ],
      "metadata": {
        "id": "wqq1CmT7kkFe"
      },
      "id": "wqq1CmT7kkFe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "09db1762",
      "metadata": {
        "id": "09db1762",
        "outputId": "27c44646-7bb5-4a67-9d26-97e88e3299c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/dinov3/dinov3_vitl16/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth\" to /root/.cache/torch/hub/checkpoints/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 403: Forbidden",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3747301723.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdinov3_vitl16_dinotxt_tet1280d20h24l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/dinov3/dinov3/hub/dinotxt.py\u001b[0m in \u001b[0;36mdinov3_vitl16_dinotxt_tet1280d20h24l\u001b[0;34m(pretrained, weights, backbone_weights, bpe_path_or_url, check_hash)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mfreeze_logit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     )\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mvision_backbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdinov3_vitl16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackbone_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     text_backbone = TextTransformer(\n\u001b[1;32m     58\u001b[0m         \u001b[0mcontext_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m77\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/dinov3/dinov3/hub/backbones.py\u001b[0m in \u001b[0;36mdinov3_vitl16\u001b[0;34m(pretrained, weights, check_hash, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0muntie_global_and_local_cls_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"version\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     return _make_dinov3_vit(\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/dinov3/dinov3/hub/backbones.py\u001b[0m in \u001b[0;36m_make_dinov3_vit\u001b[0;34m(img_size, patch_size, in_chans, compact_arch_name, pos_embed_rope_base, pos_embed_rope_min_period, pos_embed_rope_max_period, pos_embed_rope_normalize_coords, pos_embed_rope_shift_coords, pos_embed_rope_jitter_coords, pos_embed_rope_rescale_coords, pos_embed_rope_dtype, embed_dim, depth, num_heads, ffn_ratio, qkv_bias, drop_path_rate, layerscale_init, norm_layer, ffn_layer, ffn_bias, proj_bias, n_storage_tokens, mask_k_bias, pretrained, version, weights, hash, check_hash, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_path_or_url_to_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHASH_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# r is Optional[Match[str]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0mhash_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m         \u001b[0mdownload_url_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_legacy_zip_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[0mfile_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"torch.hub\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"getheaders\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    631\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
          ]
        }
      ],
      "source": [
        "# @title Monkey-patch della factory\n",
        "\n",
        "import dinov3.eval.text as dinotxt_pkg\n",
        "\n",
        "# Salva l’originale se ti serve ripristinarlo\n",
        "orig_backbone_fn = dinotxt_pkg.dinotxt_model.dinov3_vitl16  # esempio\n",
        "\n",
        "def _timm_backbone_replacement(*args, **kwargs):\n",
        "    return build_timm_dinov3_backbone(\n",
        "        timm_name=\"vit_large_patch16_dinov3.lvd_1689m\",\n",
        "        pretrained=kwargs.get(\"pretrained\", True),\n",
        "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "# Rimpiazza\n",
        "dinotxt_pkg.dinotxt_model.dinov3_vitl16 = _timm_backbone_replacement\n",
        "\n",
        "# Ora chiama il builder alto livello come prima\n",
        "model, tokenizer = dinov3_vitl16_dinotxt_tet1280d20h24l(pretrained=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e6af07f",
      "metadata": {
        "id": "9e6af07f"
      },
      "source": [
        "# Load sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2175f54e",
      "metadata": {
        "id": "2175f54e"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "from PIL import Image\n",
        "\n",
        "def load_image_from_url(url: str) -> Image:\n",
        "    with urllib.request.urlopen(url) as f:\n",
        "        return Image.open(f).convert(\"RGB\")\n",
        "\n",
        "\n",
        "EXAMPLE_IMAGE_URL = \"https://dl.fbaipublicfiles.com/dinov2/images/example.jpg\"\n",
        "img_pil = load_image_from_url(EXAMPLE_IMAGE_URL)\n",
        "display(img_pil)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c7fb8b3",
      "metadata": {
        "id": "4c7fb8b3"
      },
      "source": [
        "# Get Zero-shot classification scores on sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02560c91",
      "metadata": {
        "id": "02560c91"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from dinov3.data.transforms import make_classification_eval_transform\n",
        "\n",
        "image_preprocess = make_classification_eval_transform()\n",
        "image_tensor = torch.stack([image_preprocess(img_pil)], dim=0).cuda()\n",
        "texts = [\"photo of dogs\", \"photo of a chair\", \"photo of a bowl\", \"photo of a tupperware\"]\n",
        "class_names = [\"dog\", \"chair\", \"bowl\", \"tupperware\"]\n",
        "tokenized_texts_tensor = tokenizer.tokenize(texts).cuda()\n",
        "model = model.cuda()\n",
        "with torch.autocast('cuda', dtype=torch.float):\n",
        "    with torch.no_grad():\n",
        "        image_features = model.encode_image(image_tensor)\n",
        "        text_features = model.encode_text(tokenized_texts_tensor)\n",
        "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "similarity = (\n",
        "    text_features.cpu().float().numpy() @ image_features.cpu().float().numpy().T\n",
        ")\n",
        "print(similarity)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1774c99b",
      "metadata": {
        "id": "1774c99b"
      },
      "source": [
        "# Get patch embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4debe30",
      "metadata": {
        "id": "e4debe30"
      },
      "outputs": [],
      "source": [
        "with torch.autocast('cuda', dtype=torch.float):\n",
        "    with torch.no_grad():\n",
        "        image_class_tokens, image_patch_tokens, backbone_patch_tokens = model.encode_image_with_patch_tokens(image_tensor)\n",
        "        text_features_aligned_to_patch = model.encode_text(tokenized_texts_tensor)[:, 1024:] # Part of text features that is aligned to patch features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9929096",
      "metadata": {
        "id": "c9929096"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "B, P, D = image_patch_tokens.shape\n",
        "H = W = int(P**0.5)\n",
        "x = image_patch_tokens.movedim(2, 1).unflatten(2, (H, W)).float()  # [B, D, H, W]\n",
        "x = F.interpolate(x, size=(480, 640), mode=\"bicubic\", align_corners=False)\n",
        "x = F.normalize(x, p=2, dim=1)\n",
        "y = F.normalize(text_features_aligned_to_patch.float(), p=2, dim=1)\n",
        "per_patch_similarity_to_text = torch.einsum(\"bdhw,cd->bchw\", x, y)\n",
        "pred_idx = per_patch_similarity_to_text.argmax(1).squeeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5d099b9",
      "metadata": {
        "id": "f5d099b9"
      },
      "source": [
        "# Zero-shot classification on ImageNet1k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f23470a8",
      "metadata": {
        "id": "f23470a8"
      },
      "outputs": [],
      "source": [
        "# https://raw.githubusercontent.com/kantharajucn/CLIP-imagenet-evaluation/refs/heads/main/classes.py\n",
        "imagenet_clip_class_names= [\"tench\", \"goldfish\", \"great white shark\", \"tiger shark\", \"hammerhead shark\", \"electric ray\", \"stingray\", \"rooster\", \"hen\", \"ostrich\", \"brambling\", \"goldfinch\", \"house finch\", \"junco\", \"indigo bunting\", \"American robin\", \"bulbul\", \"jay\", \"magpie\", \"chickadee\", \"American dipper\", \"kite (bird of prey)\", \"bald eagle\", \"vulture\", \"great grey owl\", \"fire salamander\", \"smooth newt\", \"newt\", \"spotted salamander\", \"axolotl\", \"American bullfrog\", \"tree frog\", \"tailed frog\", \"loggerhead sea turtle\", \"leatherback sea turtle\", \"mud turtle\", \"terrapin\", \"box turtle\", \"banded gecko\", \"green iguana\", \"Carolina anole\", \"desert grassland whiptail lizard\", \"agama\", \"frilled-necked lizard\", \"alligator lizard\", \"Gila monster\", \"European green lizard\", \"chameleon\", \"Komodo dragon\", \"Nile crocodile\", \"American alligator\", \"triceratops\", \"worm snake\", \"ring-necked snake\", \"eastern hog-nosed snake\", \"smooth green snake\", \"kingsnake\", \"garter snake\", \"water snake\", \"vine snake\", \"night snake\", \"boa constrictor\", \"African rock python\", \"Indian cobra\", \"green mamba\", \"sea snake\", \"Saharan horned viper\", \"eastern diamondback rattlesnake\", \"sidewinder rattlesnake\", \"trilobite\", \"harvestman\", \"scorpion\", \"yellow garden spider\", \"barn spider\", \"European garden spider\", \"southern black widow\", \"tarantula\", \"wolf spider\", \"tick\", \"centipede\", \"black grouse\", \"ptarmigan\", \"ruffed grouse\", \"prairie grouse\", \"peafowl\", \"quail\", \"partridge\", \"african grey parrot\", \"macaw\", \"sulphur-crested cockatoo\", \"lorikeet\", \"coucal\", \"bee eater\", \"hornbill\", \"hummingbird\", \"jacamar\", \"toucan\", \"duck\", \"red-breasted merganser\", \"goose\", \"black swan\", \"tusker\", \"echidna\", \"platypus\", \"wallaby\", \"koala\", \"wombat\", \"jellyfish\", \"sea anemone\", \"brain coral\", \"flatworm\", \"nematode\", \"conch\", \"snail\", \"slug\", \"sea slug\", \"chiton\", \"chambered nautilus\", \"Dungeness crab\", \"rock crab\", \"fiddler crab\", \"red king crab\", \"American lobster\", \"spiny lobster\", \"crayfish\", \"hermit crab\", \"isopod\", \"white stork\", \"black stork\", \"spoonbill\", \"flamingo\", \"little blue heron\", \"great egret\", \"bittern bird\", \"crane bird\", \"limpkin\", \"common gallinule\", \"American coot\", \"bustard\", \"ruddy turnstone\", \"dunlin\", \"common redshank\", \"dowitcher\", \"oystercatcher\", \"pelican\", \"king penguin\", \"albatross\", \"grey whale\", \"killer whale\", \"dugong\", \"sea lion\", \"Chihuahua\", \"Japanese Chin\", \"Maltese\", \"Pekingese\", \"Shih Tzu\", \"King Charles Spaniel\", \"Papillon\", \"toy terrier\", \"Rhodesian Ridgeback\", \"Afghan Hound\", \"Basset Hound\", \"Beagle\", \"Bloodhound\", \"Bluetick Coonhound\", \"Black and Tan Coonhound\", \"Treeing Walker Coonhound\", \"English foxhound\", \"Redbone Coonhound\", \"borzoi\", \"Irish Wolfhound\", \"Italian Greyhound\", \"Whippet\", \"Ibizan Hound\", \"Norwegian Elkhound\", \"Otterhound\", \"Saluki\", \"Scottish Deerhound\", \"Weimaraner\", \"Staffordshire Bull Terrier\", \"American Staffordshire Terrier\", \"Bedlington Terrier\", \"Border Terrier\", \"Kerry Blue Terrier\", \"Irish Terrier\", \"Norfolk Terrier\", \"Norwich Terrier\", \"Yorkshire Terrier\", \"Wire Fox Terrier\", \"Lakeland Terrier\", \"Sealyham Terrier\", \"Airedale Terrier\", \"Cairn Terrier\", \"Australian Terrier\", \"Dandie Dinmont Terrier\", \"Boston Terrier\", \"Miniature Schnauzer\", \"Giant Schnauzer\", \"Standard Schnauzer\", \"Scottish Terrier\", \"Tibetan Terrier\", \"Australian Silky Terrier\", \"Soft-coated Wheaten Terrier\", \"West Highland White Terrier\", \"Lhasa Apso\", \"Flat-Coated Retriever\", \"Curly-coated Retriever\", \"Golden Retriever\", \"Labrador Retriever\", \"Chesapeake Bay Retriever\", \"German Shorthaired Pointer\", \"Vizsla\", \"English Setter\", \"Irish Setter\", \"Gordon Setter\", \"Brittany dog\", \"Clumber Spaniel\", \"English Springer Spaniel\", \"Welsh Springer Spaniel\", \"Cocker Spaniel\", \"Sussex Spaniel\", \"Irish Water Spaniel\", \"Kuvasz\", \"Schipperke\", \"Groenendael dog\", \"Malinois\", \"Briard\", \"Australian Kelpie\", \"Komondor\", \"Old English Sheepdog\", \"Shetland Sheepdog\", \"collie\", \"Border Collie\", \"Bouvier des Flandres dog\", \"Rottweiler\", \"German Shepherd Dog\", \"Dobermann\", \"Miniature Pinscher\", \"Greater Swiss Mountain Dog\", \"Bernese Mountain Dog\", \"Appenzeller Sennenhund\", \"Entlebucher Sennenhund\", \"Boxer\", \"Bullmastiff\", \"Tibetan Mastiff\", \"French Bulldog\", \"Great Dane\", \"St. Bernard\", \"husky\", \"Alaskan Malamute\", \"Siberian Husky\", \"Dalmatian\", \"Affenpinscher\", \"Basenji\", \"pug\", \"Leonberger\", \"Newfoundland dog\", \"Great Pyrenees dog\", \"Samoyed\", \"Pomeranian\", \"Chow Chow\", \"Keeshond\", \"brussels griffon\", \"Pembroke Welsh Corgi\", \"Cardigan Welsh Corgi\", \"Toy Poodle\", \"Miniature Poodle\", \"Standard Poodle\", \"Mexican hairless dog (xoloitzcuintli)\", \"grey wolf\", \"Alaskan tundra wolf\", \"red wolf or maned wolf\", \"coyote\", \"dingo\", \"dhole\", \"African wild dog\", \"hyena\", \"red fox\", \"kit fox\", \"Arctic fox\", \"grey fox\", \"tabby cat\", \"tiger cat\", \"Persian cat\", \"Siamese cat\", \"Egyptian Mau\", \"cougar\", \"lynx\", \"leopard\", \"snow leopard\", \"jaguar\", \"lion\", \"tiger\", \"cheetah\", \"brown bear\", \"American black bear\", \"polar bear\", \"sloth bear\", \"mongoose\", \"meerkat\", \"tiger beetle\", \"ladybug\", \"ground beetle\", \"longhorn beetle\", \"leaf beetle\", \"dung beetle\", \"rhinoceros beetle\", \"weevil\", \"fly\", \"bee\", \"ant\", \"grasshopper\", \"cricket insect\", \"stick insect\", \"cockroach\", \"praying mantis\", \"cicada\", \"leafhopper\", \"lacewing\", \"dragonfly\", \"damselfly\", \"red admiral butterfly\", \"ringlet butterfly\", \"monarch butterfly\", \"small white butterfly\", \"sulphur butterfly\", \"gossamer-winged butterfly\", \"starfish\", \"sea urchin\", \"sea cucumber\", \"cottontail rabbit\", \"hare\", \"Angora rabbit\", \"hamster\", \"porcupine\", \"fox squirrel\", \"marmot\", \"beaver\", \"guinea pig\", \"common sorrel horse\", \"zebra\", \"pig\", \"wild boar\", \"warthog\", \"hippopotamus\", \"ox\", \"water buffalo\", \"bison\", \"ram (adult male sheep)\", \"bighorn sheep\", \"Alpine ibex\", \"hartebeest\", \"impala (antelope)\", \"gazelle\", \"arabian camel\", \"llama\", \"weasel\", \"mink\", \"European polecat\", \"black-footed ferret\", \"otter\", \"skunk\", \"badger\", \"armadillo\", \"three-toed sloth\", \"orangutan\", \"gorilla\", \"chimpanzee\", \"gibbon\", \"siamang\", \"guenon\", \"patas monkey\", \"baboon\", \"macaque\", \"langur\", \"black-and-white colobus\", \"proboscis monkey\", \"marmoset\", \"white-headed capuchin\", \"howler monkey\", \"titi monkey\", \"Geoffroy's spider monkey\", \"common squirrel monkey\", \"ring-tailed lemur\", \"indri\", \"Asian elephant\", \"African bush elephant\", \"red panda\", \"giant panda\", \"snoek fish\", \"eel\", \"silver salmon\", \"rock beauty fish\", \"clownfish\", \"sturgeon\", \"gar fish\", \"lionfish\", \"pufferfish\", \"abacus\", \"abaya\", \"academic gown\", \"accordion\", \"acoustic guitar\", \"aircraft carrier\", \"airliner\", \"airship\", \"altar\", \"ambulance\", \"amphibious vehicle\", \"analog clock\", \"apiary\", \"apron\", \"trash can\", \"assault rifle\", \"backpack\", \"bakery\", \"balance beam\", \"balloon\", \"ballpoint pen\", \"Band-Aid\", \"banjo\", \"baluster / handrail\", \"barbell\", \"barber chair\", \"barbershop\", \"barn\", \"barometer\", \"barrel\", \"wheelbarrow\", \"baseball\", \"basketball\", \"bassinet\", \"bassoon\", \"swimming cap\", \"bath towel\", \"bathtub\", \"station wagon\", \"lighthouse\", \"beaker\", \"military hat (bearskin or shako)\", \"beer bottle\", \"beer glass\", \"bell tower\", \"baby bib\", \"tandem bicycle\", \"bikini\", \"ring binder\", \"binoculars\", \"birdhouse\", \"boathouse\", \"bobsleigh\", \"bolo tie\", \"poke bonnet\", \"bookcase\", \"bookstore\", \"bottle cap\", \"hunting bow\", \"bow tie\", \"brass memorial plaque\", \"bra\", \"breakwater\", \"breastplate\", \"broom\", \"bucket\", \"buckle\", \"bulletproof vest\", \"high-speed train\", \"butcher shop\", \"taxicab\", \"cauldron\", \"candle\", \"cannon\", \"canoe\", \"can opener\", \"cardigan\", \"car mirror\", \"carousel\", \"tool kit\", \"cardboard box / carton\", \"car wheel\", \"automated teller machine\", \"cassette\", \"cassette player\", \"castle\", \"catamaran\", \"CD player\", \"cello\", \"mobile phone\", \"chain\", \"chain-link fence\", \"chain mail\", \"chainsaw\", \"storage chest\", \"chiffonier\", \"bell or wind chime\", \"china cabinet\", \"Christmas stocking\", \"church\", \"movie theater\", \"cleaver\", \"cliff dwelling\", \"cloak\", \"clogs\", \"cocktail shaker\", \"coffee mug\", \"coffeemaker\", \"spiral or coil\", \"combination lock\", \"computer keyboard\", \"candy store\", \"container ship\", \"convertible\", \"corkscrew\", \"cornet\", \"cowboy boot\", \"cowboy hat\", \"cradle\", \"construction crane\", \"crash helmet\", \"crate\", \"infant bed\", \"Crock Pot\", \"croquet ball\", \"crutch\", \"cuirass\", \"dam\", \"desk\", \"desktop computer\", \"rotary dial telephone\", \"diaper\", \"digital clock\", \"digital watch\", \"dining table\", \"dishcloth\", \"dishwasher\", \"disc brake\", \"dock\", \"dog sled\", \"dome\", \"doormat\", \"drilling rig\", \"drum\", \"drumstick\", \"dumbbell\", \"Dutch oven\", \"electric fan\", \"electric guitar\", \"electric locomotive\", \"entertainment center\", \"envelope\", \"espresso machine\", \"face powder\", \"feather boa\", \"filing cabinet\", \"fireboat\", \"fire truck\", \"fire screen\", \"flagpole\", \"flute\", \"folding chair\", \"football helmet\", \"forklift\", \"fountain\", \"fountain pen\", \"four-poster bed\", \"freight car\", \"French horn\", \"frying pan\", \"fur coat\", \"garbage truck\", \"gas mask or respirator\", \"gas pump\", \"goblet\", \"go-kart\", \"golf ball\", \"golf cart\", \"gondola\", \"gong\", \"gown\", \"grand piano\", \"greenhouse\", \"radiator grille\", \"grocery store\", \"guillotine\", \"hair clip\", \"hair spray\", \"half-track\", \"hammer\", \"hamper\", \"hair dryer\", \"hand-held computer\", \"handkerchief\", \"hard disk drive\", \"harmonica\", \"harp\", \"combine harvester\", \"hatchet\", \"holster\", \"home theater\", \"honeycomb\", \"hook\", \"hoop skirt\", \"gymnastic horizontal bar\", \"horse-drawn vehicle\", \"hourglass\", \"iPod\", \"clothes iron\", \"carved pumpkin\", \"jeans\", \"jeep\", \"T-shirt\", \"jigsaw puzzle\", \"rickshaw\", \"joystick\", \"kimono\", \"knee pad\", \"knot\", \"lab coat\", \"ladle\", \"lampshade\", \"laptop computer\", \"lawn mower\", \"lens cap\", \"letter opener\", \"library\", \"lifeboat\", \"lighter\", \"limousine\", \"ocean liner\", \"lipstick\", \"slip-on shoe\", \"lotion\", \"music speaker\", \"loupe magnifying glass\", \"sawmill\", \"magnetic compass\", \"messenger bag\", \"mailbox\", \"tights\", \"one-piece bathing suit\", \"manhole cover\", \"maraca\", \"marimba\", \"mask\", \"matchstick\", \"maypole\", \"maze\", \"measuring cup\", \"medicine cabinet\", \"megalith\", \"microphone\", \"microwave oven\", \"military uniform\", \"milk can\", \"minibus\", \"miniskirt\", \"minivan\", \"missile\", \"mitten\", \"mixing bowl\", \"mobile home\", \"ford model t\", \"modem\", \"monastery\", \"monitor\", \"moped\", \"mortar and pestle\", \"graduation cap\", \"mosque\", \"mosquito net\", \"vespa\", \"mountain bike\", \"tent\", \"computer mouse\", \"mousetrap\", \"moving van\", \"muzzle\", \"metal nail\", \"neck brace\", \"necklace\", \"baby pacifier\", \"notebook computer\", \"obelisk\", \"oboe\", \"ocarina\", \"odometer\", \"oil filter\", \"pipe organ\", \"oscilloscope\", \"overskirt\", \"bullock cart\", \"oxygen mask\", \"product packet / packaging\", \"paddle\", \"paddle wheel\", \"padlock\", \"paintbrush\", \"pajamas\", \"palace\", \"pan flute\", \"paper towel\", \"parachute\", \"parallel bars\", \"park bench\", \"parking meter\", \"railroad car\", \"patio\", \"payphone\", \"pedestal\", \"pencil case\", \"pencil sharpener\", \"perfume\", \"Petri dish\", \"photocopier\", \"plectrum\", \"Pickelhaube\", \"picket fence\", \"pickup truck\", \"pier\", \"piggy bank\", \"pill bottle\", \"pillow\", \"ping-pong ball\", \"pinwheel\", \"pirate ship\", \"drink pitcher\", \"block plane\", \"planetarium\", \"plastic bag\", \"plate rack\", \"farm plow\", \"plunger\", \"Polaroid camera\", \"pole\", \"police van\", \"poncho\", \"pool table\", \"soda bottle\", \"plant pot\", \"potter's wheel\", \"power drill\", \"prayer rug\", \"printer\", \"prison\", \"missile\", \"projector\", \"hockey puck\", \"punching bag\", \"purse\", \"quill\", \"quilt\", \"race car\", \"racket\", \"radiator\", \"radio\", \"radio telescope\", \"rain barrel\", \"recreational vehicle\", \"fishing casting reel\", \"reflex camera\", \"refrigerator\", \"remote control\", \"restaurant\", \"revolver\", \"rifle\", \"rocking chair\", \"rotisserie\", \"eraser\", \"rugby ball\", \"ruler measuring stick\", \"sneaker\", \"safe\", \"safety pin\", \"salt shaker\", \"sandal\", \"sarong\", \"saxophone\", \"scabbard\", \"weighing scale\", \"school bus\", \"schooner\", \"scoreboard\", \"CRT monitor\", \"screw\", \"screwdriver\", \"seat belt\", \"sewing machine\", \"shield\", \"shoe store\", \"shoji screen / room divider\", \"shopping basket\", \"shopping cart\", \"shovel\", \"shower cap\", \"shower curtain\", \"ski\", \"balaclava ski mask\", \"sleeping bag\", \"slide rule\", \"sliding door\", \"slot machine\", \"snorkel\", \"snowmobile\", \"snowplow\", \"soap dispenser\", \"soccer ball\", \"sock\", \"solar thermal collector\", \"sombrero\", \"soup bowl\", \"keyboard space bar\", \"space heater\", \"space shuttle\", \"spatula\", \"motorboat\", \"spider web\", \"spindle\", \"sports car\", \"spotlight\", \"stage\", \"steam locomotive\", \"through arch bridge\", \"steel drum\", \"stethoscope\", \"scarf\", \"stone wall\", \"stopwatch\", \"stove\", \"strainer\", \"tram\", \"stretcher\", \"couch\", \"stupa\", \"submarine\", \"suit\", \"sundial\", \"sunglasses\", \"sunglasses\", \"sunscreen\", \"suspension bridge\", \"mop\", \"sweatshirt\", \"swim trunks / shorts\", \"swing\", \"electrical switch\", \"syringe\", \"table lamp\", \"tank\", \"tape player\", \"teapot\", \"teddy bear\", \"television\", \"tennis ball\", \"thatched roof\", \"front curtain\", \"thimble\", \"threshing machine\", \"throne\", \"tile roof\", \"toaster\", \"tobacco shop\", \"toilet seat\", \"torch\", \"totem pole\", \"tow truck\", \"toy store\", \"tractor\", \"semi-trailer truck\", \"tray\", \"trench coat\", \"tricycle\", \"trimaran\", \"tripod\", \"triumphal arch\", \"trolleybus\", \"trombone\", \"hot tub\", \"turnstile\", \"typewriter keyboard\", \"umbrella\", \"unicycle\", \"upright piano\", \"vacuum cleaner\", \"vase\", \"vaulted or arched ceiling\", \"velvet fabric\", \"vending machine\", \"vestment\", \"viaduct\", \"violin\", \"volleyball\", \"waffle iron\", \"wall clock\", \"wallet\", \"wardrobe\", \"military aircraft\", \"sink\", \"washing machine\", \"water bottle\", \"water jug\", \"water tower\", \"whiskey jug\", \"whistle\", \"hair wig\", \"window screen\", \"window shade\", \"Windsor tie\", \"wine bottle\", \"airplane wing\", \"wok\", \"wooden spoon\", \"wool\", \"split-rail fence\", \"shipwreck\", \"sailboat\", \"yurt\", \"website\", \"comic book\", \"crossword\", \"traffic or street sign\", \"traffic light\", \"dust jacket\", \"menu\", \"plate\", \"guacamole\", \"consomme\", \"hot pot\", \"trifle\", \"ice cream\", \"popsicle\", \"baguette\", \"bagel\", \"pretzel\", \"cheeseburger\", \"hot dog\", \"mashed potatoes\", \"cabbage\", \"broccoli\", \"cauliflower\", \"zucchini\", \"spaghetti squash\", \"acorn squash\", \"butternut squash\", \"cucumber\", \"artichoke\", \"bell pepper\", \"cardoon\", \"mushroom\", \"Granny Smith apple\", \"strawberry\", \"orange\", \"lemon\", \"fig\", \"pineapple\", \"banana\", \"jackfruit\", \"cherimoya (custard apple)\", \"pomegranate\", \"hay\", \"carbonara\", \"chocolate syrup\", \"dough\", \"meatloaf\", \"pizza\", \"pot pie\", \"burrito\", \"red wine\", \"espresso\", \"tea cup\", \"eggnog\", \"mountain\", \"bubble\", \"cliff\", \"coral reef\", \"geyser\", \"lakeshore\", \"promontory\", \"sandbar\", \"beach\", \"valley\", \"volcano\", \"baseball player\", \"bridegroom\", \"scuba diver\", \"rapeseed\", \"daisy\", \"yellow lady's slipper\", \"corn\", \"acorn\", \"rose hip\", \"horse chestnut seed\", \"coral fungus\", \"agaric\", \"gyromitra\", \"stinkhorn mushroom\", \"earth star fungus\", \"hen of the woods mushroom\", \"bolete\", \"corn cob\", \"toilet paper\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77388348",
      "metadata": {
        "id": "77388348"
      },
      "outputs": [],
      "source": [
        "# The following comes from here: https://github.com/mlfoundations/open_clip/blob/main/src/open_clip/zero_shot_metadata.py\n",
        "# Original reference: https://github.com/openai/CLIP/blob/main/notebooks/Prompt_Engineering_for_ImageNet.ipynb\n",
        "openai_imagenet_templates = (\n",
        "    lambda c: f\"a bad photo of a {c}.\",\n",
        "    lambda c: f\"a photo of many {c}.\",\n",
        "    lambda c: f\"a sculpture of a {c}.\",\n",
        "    lambda c: f\"a photo of the hard to see {c}.\",\n",
        "    lambda c: f\"a low resolution photo of the {c}.\",\n",
        "    lambda c: f\"a rendering of a {c}.\",\n",
        "    lambda c: f\"graffiti of a {c}.\",\n",
        "    lambda c: f\"a bad photo of the {c}.\",\n",
        "    lambda c: f\"a cropped photo of the {c}.\",\n",
        "    lambda c: f\"a tattoo of a {c}.\",\n",
        "    lambda c: f\"the embroidered {c}.\",\n",
        "    lambda c: f\"a photo of a hard to see {c}.\",\n",
        "    lambda c: f\"a bright photo of a {c}.\",\n",
        "    lambda c: f\"a photo of a clean {c}.\",\n",
        "    lambda c: f\"a photo of a dirty {c}.\",\n",
        "    lambda c: f\"a dark photo of the {c}.\",\n",
        "    lambda c: f\"a drawing of a {c}.\",\n",
        "    lambda c: f\"a photo of my {c}.\",\n",
        "    lambda c: f\"the plastic {c}.\",\n",
        "    lambda c: f\"a photo of the cool {c}.\",\n",
        "    lambda c: f\"a close-up photo of a {c}.\",\n",
        "    lambda c: f\"a black and white photo of the {c}.\",\n",
        "    lambda c: f\"a painting of the {c}.\",\n",
        "    lambda c: f\"a painting of a {c}.\",\n",
        "    lambda c: f\"a pixelated photo of the {c}.\",\n",
        "    lambda c: f\"a sculpture of the {c}.\",\n",
        "    lambda c: f\"a bright photo of the {c}.\",\n",
        "    lambda c: f\"a cropped photo of a {c}.\",\n",
        "    lambda c: f\"a plastic {c}.\",\n",
        "    lambda c: f\"a photo of the dirty {c}.\",\n",
        "    lambda c: f\"a jpeg corrupted photo of a {c}.\",\n",
        "    lambda c: f\"a blurry photo of the {c}.\",\n",
        "    lambda c: f\"a photo of the {c}.\",\n",
        "    lambda c: f\"a good photo of the {c}.\",\n",
        "    lambda c: f\"a rendering of the {c}.\",\n",
        "    lambda c: f\"a {c} in a video game.\",\n",
        "    lambda c: f\"a photo of one {c}.\",\n",
        "    lambda c: f\"a doodle of a {c}.\",\n",
        "    lambda c: f\"a close-up photo of the {c}.\",\n",
        "    lambda c: f\"a photo of a {c}.\",\n",
        "    lambda c: f\"the origami {c}.\",\n",
        "    lambda c: f\"the {c} in a video game.\",\n",
        "    lambda c: f\"a sketch of a {c}.\",\n",
        "    lambda c: f\"a doodle of the {c}.\",\n",
        "    lambda c: f\"a origami {c}.\",\n",
        "    lambda c: f\"a low resolution photo of a {c}.\",\n",
        "    lambda c: f\"the toy {c}.\",\n",
        "    lambda c: f\"a rendition of the {c}.\",\n",
        "    lambda c: f\"a photo of the clean {c}.\",\n",
        "    lambda c: f\"a photo of a large {c}.\",\n",
        "    lambda c: f\"a rendition of a {c}.\",\n",
        "    lambda c: f\"a photo of a nice {c}.\",\n",
        "    lambda c: f\"a photo of a weird {c}.\",\n",
        "    lambda c: f\"a blurry photo of a {c}.\",\n",
        "    lambda c: f\"a cartoon {c}.\",\n",
        "    lambda c: f\"art of a {c}.\",\n",
        "    lambda c: f\"a sketch of the {c}.\",\n",
        "    lambda c: f\"a embroidered {c}.\",\n",
        "    lambda c: f\"a pixelated photo of a {c}.\",\n",
        "    lambda c: f\"itap of the {c}.\",\n",
        "    lambda c: f\"a jpeg corrupted photo of the {c}.\",\n",
        "    lambda c: f\"a good photo of a {c}.\",\n",
        "    lambda c: f\"a plushie {c}.\",\n",
        "    lambda c: f\"a photo of the nice {c}.\",\n",
        "    lambda c: f\"a photo of the small {c}.\",\n",
        "    lambda c: f\"a photo of the weird {c}.\",\n",
        "    lambda c: f\"the cartoon {c}.\",\n",
        "    lambda c: f\"art of the {c}.\",\n",
        "    lambda c: f\"a drawing of the {c}.\",\n",
        "    lambda c: f\"a photo of the large {c}.\",\n",
        "    lambda c: f\"a black and white photo of a {c}.\",\n",
        "    lambda c: f\"the plushie {c}.\",\n",
        "    lambda c: f\"a dark photo of a {c}.\",\n",
        "    lambda c: f\"itap of a {c}.\",\n",
        "    lambda c: f\"graffiti of the {c}.\",\n",
        "    lambda c: f\"a toy {c}.\",\n",
        "    lambda c: f\"itap of my {c}.\",\n",
        "    lambda c: f\"a photo of a cool {c}.\",\n",
        "    lambda c: f\"a photo of a small {c}.\",\n",
        "    lambda c: f\"a tattoo of the {c}.\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e0a1e8",
      "metadata": {
        "id": "38e0a1e8"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from dinov3.data.transforms import make_classification_eval_transform\n",
        "\n",
        "image_preprocess = make_classification_eval_transform(resize_size=512, crop_size=512)\n",
        "# Please update the following directory to the root of ImageNet1k val dataset.\n",
        "imagenet_val_root_dir = \"<PATH/TO/IMAGENET/VAL/ROOT_DIR>\"\n",
        "val_dataset = ImageFolder(imagenet_val_root_dir, image_preprocess)\n",
        "model = model.eval().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c80b1674",
      "metadata": {
        "id": "c80b1674"
      },
      "outputs": [],
      "source": [
        "def zeroshot_classifier(classnames, templates, tokenizer):\n",
        "    with torch.no_grad():\n",
        "        zeroshot_weights = []\n",
        "        for classname in classnames:\n",
        "            texts = [template(classname) for template in templates] #format with class\n",
        "            texts = tokenizer.tokenize(texts).cuda() #tokenize\n",
        "            class_embeddings = model.encode_text(texts) #embed with text encoder\n",
        "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
        "            class_embedding = class_embeddings.mean(dim=0)\n",
        "            class_embedding /= class_embedding.norm()\n",
        "            zeroshot_weights.append(class_embedding)\n",
        "        zeroshot_weights = torch.stack(zeroshot_weights, dim=1).cuda()\n",
        "    return zeroshot_weights\n",
        "zeroshot_weights = zeroshot_classifier(imagenet_clip_class_names, openai_imagenet_templates, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9544facf",
      "metadata": {
        "id": "9544facf"
      },
      "outputs": [],
      "source": [
        "class_name_to_ids = {class_name:idx for idx, class_name in enumerate(imagenet_clip_class_names)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8c2b370",
      "metadata": {
        "id": "b8c2b370"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    pred = output.topk(max(topk), 1, True, True)[1].t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "    return [correct[:k].reshape(-1).sum(0, keepdim=True) for k in topk]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "727bed3a",
      "metadata": {
        "id": "727bed3a"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "class_ids = []\n",
        "batch_size = 64\n",
        "num_workers = 8\n",
        "top1, top5, n = 0., 0., 0.\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "for images, targets in val_loader:\n",
        "    with torch.autocast('cuda', dtype=torch.float):\n",
        "        with torch.no_grad():\n",
        "            image_features = model.encode_image(images.cuda())\n",
        "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "            logits = 100. * image_features @ zeroshot_weights\n",
        "            acc1, acc5 = accuracy(logits, targets.cuda(), topk=(1, 5))\n",
        "            top1 += acc1\n",
        "            top5 += acc5\n",
        "            n += len(images)\n",
        "    images = []\n",
        "    class_ids = []\n",
        "top1 = (top1.item() / n) * 100\n",
        "top5 = (top5.item() / n) * 100\n",
        "print(f\"Top-1 accuracy: {top1}\")\n",
        "print(f\"Top-5 accuracy: {top5}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dinov3_minimal",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}