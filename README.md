# ARGO_Vision_CODEMOTION_2025

This repository is associated with the **CODEMOTION 2025 Workshop**
ðŸŽ“ **"From Pixel to Pixel to Features: One Backbone to Rule Them All"**

The workshop will alternate between slides and practical references contained in this repository (external links and Jupyter notebooks).

ðŸ’¡ **Tip:**
Fork this repository if you want to modify the code and save your changes directly to your own GitHub account.

---

## ðŸ“˜ Workshop Flow

1. **Explore the Terminology of the Learning Process**
   ðŸ”— [TensorFlow Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=spiral&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.41584&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=true&cosY=false&sinY=true&collectStats=false&problem=classification&initZero=false&hideText=false)

2. **Visualization of CNNs**
   ðŸ”— [3D CNN Visualization](https://adamharley.com/nn_vis/cnn/3d.html)

---

## ðŸš€ Open the Notebooks Quickly

To open a notebook directly in **Google Colab**,
simply insert `tocolab` between `"github"` and `"com"` in the URL.

Example:

```
https://github.com/plana93/ARGO_Vision_CODEMOTION_2025/blob/main/notebooks/3_sam2.ipynb
```

becomes:

```
https://githubtocolab.com/plana93/ARGO_Vision_CODEMOTION_2025/blob/main/notebooks/3_sam2.ipynb
```

---

## ðŸ“‚ Notebook Index

### ðŸ§  Attention & Multimodal Models

* **Self-Attention** â†’ `notebooks/1_self_attention.ipynb`
* **CLIP Model** â†’ `notebooks/2_clip_model.ipynb`

### ðŸ©» Segmentation Models

* **SAM2 (Segment Anything Model v2)** â†’ `notebooks/3_sam2.ipynb`

### ðŸ¦– DINOv3 Feature Extraction & Matching

* **DINOv3 â€“ PCA Exploration** â†’ `notebooks/4_dinov3_pca.ipynb`
* **DINOv3 â€“ Dense & Sparse Matching** â†’ `notebooks/5_dinov3_dense_sparse_matching.ipynb`
* **DINOv3 â€“ Training-Free Object Detection** â†’ `notebooks/6_dinov3_training_free_detection.ipynb`

---